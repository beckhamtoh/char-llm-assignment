{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "LNS1ztqUUrw7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNS1ztqUUrw7",
        "outputId": "21ffc255-cbb8-406b-e302-508d14d5848f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'char-llm-assignment'...\n",
            "remote: Enumerating objects: 15, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 15 (delta 0), reused 12 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (15/15), 30.14 MiB | 32.11 MiB/s, done.\n",
            "/content/char-llm-assignment\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/beckhamtoh/char-llm-assignment.git\n",
        "%cd char-llm-assignment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e2def0f4",
      "metadata": {
        "id": "e2def0f4"
      },
      "outputs": [],
      "source": [
        "# Enable autoreload of local Python modules (e.g., models)\n",
        "# %load_ext autoreload\n",
        "# %autoreload 2\n",
        "\n",
        "# manual reload for local modules\n",
        "import importlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5001b05",
      "metadata": {
        "id": "d5001b05"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "import numpy as np\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import optax\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# local imports\n",
        "import models.models as models\n",
        "import util.generation as generation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "906db4f2",
      "metadata": {
        "id": "906db4f2"
      },
      "outputs": [],
      "source": [
        "# initialize the jax random key\n",
        "key = jax.random.key(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "762a1c8f",
      "metadata": {
        "id": "762a1c8f"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "86825275",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86825275",
        "outputId": "51b635db-0434-44d4-ccc9-aa0b1093834e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of training text: 90_000_000 characters\n",
            "Length of test text: 5_000_000 characters\n"
          ]
        }
      ],
      "source": [
        "# load the ./data/text8_train.txt and ./data/text8_test.txt files\n",
        "with open(\"./data/text8_train.txt\", \"r\") as f:\n",
        "    train_text = f.read()\n",
        "with open(\"./data/text8_test.txt\", \"r\") as f:\n",
        "    test_text = f.read()\n",
        "\n",
        "# print the length of the training text and test text\n",
        "print(f\"Length of training text: {len(train_text):_} characters\")\n",
        "print(f\"Length of test text: {len(test_text):_} characters\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bfdca63",
      "metadata": {
        "id": "7bfdca63"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "34b1eafe",
      "metadata": {
        "id": "34b1eafe"
      },
      "outputs": [],
      "source": [
        "# Build vocabulary (lowercase + space + a few punctuations)\n",
        "char_set = list(\"abcdefghijklmnopqrstuvwxyz \")\n",
        "char_to_int = {ch:i for i,ch in enumerate(char_set)}\n",
        "int_to_char = {i:ch for ch,i in char_to_int.items()}\n",
        "\n",
        "def encode(s):\n",
        "    \"\"\"Encode string to array of integers\"\"\"\n",
        "    ids = [char_to_int[c] for c in s]\n",
        "    return np.array(ids, dtype=np.uint8)  # use np.uint8 to save space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "42b5af70",
      "metadata": {
        "id": "42b5af70"
      },
      "outputs": [],
      "source": [
        "# encode the text\n",
        "train_text_int = encode(train_text)\n",
        "test_text_int = encode(test_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "6458536d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6458536d",
        "outputId": "f7572de8-c91b-4039-cedd-c6aab21535c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "of the illness and went to the fragrant mountain to give thanks to the person when he discovered that his own daughter gave up h\n",
            "\n",
            "together they performed the arcade fire s song wake up from their album funeral he joined them again on one five september singi\n",
            "\n",
            "ro asiatic language phylum its closest relatives are the berber semitic and beja groups of languages written records of the egyp\n",
            "\n",
            "es were produced between about one nine three zero and one nine three five but the concept was abandonded because of its limited\n",
            "\n",
            "xt is read aloud twice during the celebration setting the biblical book of esther is set in the third year of ahasuerus a king o\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# sanity check: display a few random characters from the training text\n",
        "T = 128\n",
        "for _ in range(5):\n",
        "    # choose random position in text\n",
        "    N = np.random.randint(low=0, high=len(train_text)-T)\n",
        "    print(train_text[N:N+T])\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7724c34b",
      "metadata": {
        "id": "7724c34b"
      },
      "source": [
        "# Create a basic Transformer model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b11b772b",
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_train_state(rng, vocab_size=27, d_model=64, n_layers=6, n_heads=8, max_len=128, pos_encoding_type='learned'):\n",
        "    # create a basic Transformer model with specified positional encoding\n",
        "    model = models.DecoderOnlyTransformer(\n",
        "        vocab_size, \n",
        "        d_model, \n",
        "        n_layers, \n",
        "        n_heads, \n",
        "        max_len,\n",
        "        pos_encoding_type=pos_encoding_type  \n",
        "    )\n",
        "    # create a dummy input for initialization\n",
        "    dummy = jnp.zeros((1, min(16, max_len)), dtype=jnp.int32)\n",
        "    # pass the dummy input to the model to initialize the parameters\n",
        "    params = model.init({\"params\": rng}, dummy)[\"params\"]\n",
        "    return model, params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3ea2291",
      "metadata": {
        "id": "c3ea2291"
      },
      "outputs": [],
      "source": [
        "# vocab size\n",
        "vocab_size= len(char_set)\n",
        "\n",
        "# internal model dimensions\n",
        "d_model=256\n",
        "\n",
        "# number of attention heads\n",
        "n_heads=8\n",
        "\n",
        "# number of Transformer layers\n",
        "n_layers=2\n",
        "\n",
        "# maximum sequence length\n",
        "max_len=128\n",
        "\n",
        "# learning rate for the optimizer\n",
        "learning_rate = 0.001"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0213425",
      "metadata": {
        "id": "b0213425"
      },
      "source": [
        "# Loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "ab7a3479",
      "metadata": {
        "id": "ab7a3479"
      },
      "outputs": [],
      "source": [
        "@jax.jit\n",
        "def loss_and_metrics(logits, targets):\n",
        "    \"\"\"Compute cross-entropy loss and accuracy.\n",
        "\n",
        "    Assumes `targets` contains only valid integer class ids in [0, V-1] (no -1 ignore tokens).\n",
        "\n",
        "    Args:\n",
        "      logits: (B, T, V) float array of unnormalized scores.\n",
        "      targets: (B, T) integer array with ground-truth class ids.\n",
        "\n",
        "    Returns:\n",
        "      loss: scalar average cross-entropy over all positions.\n",
        "      metrics: dict with keys \"loss\" and \"acc\" (both scalars).\n",
        "    \"\"\"\n",
        "    # Flatten batch/time dims so optax works on shape (N, V) and (N,)\n",
        "    vocab = logits.shape[-1]\n",
        "    flat_logits = logits.reshape(-1, vocab)\n",
        "    flat_targets = targets.reshape(-1)\n",
        "\n",
        "    # Per-position cross-entropy, then mean over all positions\n",
        "    per_pos = optax.softmax_cross_entropy_with_integer_labels(flat_logits, flat_targets)\n",
        "    loss = per_pos.mean()\n",
        "\n",
        "    # prediction over all positions\n",
        "    preds = jnp.argmax(logits, axis=-1)  # (B, T)\n",
        "\n",
        "    # compute accuracy over only the last position\n",
        "    is_match = preds == targets\n",
        "\n",
        "    # Accuracy over all positions\n",
        "    acc_all = jnp.mean(is_match.astype(jnp.float32))\n",
        "\n",
        "    # Accuracy over only last position\n",
        "    acc_last = jnp.mean(is_match.astype(jnp.float32)[:,-1])\n",
        "\n",
        "    return loss, {\"loss\": loss, \"acc\": acc_all, \"acc_last\": acc_last}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05221147",
      "metadata": {
        "id": "05221147"
      },
      "source": [
        "# Optimization step:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "b720c846",
      "metadata": {
        "id": "b720c846"
      },
      "outputs": [],
      "source": [
        "# create an update function\n",
        "def train_step(params, opt_state, x, y, tx):\n",
        "    \"\"\"Single optimization step using optax optimizer.\n",
        "\n",
        "    Args:\n",
        "      params: pytree of model parameters.\n",
        "      opt_state: optax optimizer state corresponding to `params`.\n",
        "      x: (B, T) int array input tokens.\n",
        "      y: (B, T) int array target tokens.\n",
        "      tx: optax.GradientTransformation (already initialized).\n",
        "\n",
        "    Returns:\n",
        "      new_params: updated parameters after one gradient step.\n",
        "      new_opt_state: updated optimizer state.\n",
        "      metrics: dict of scalar metrics (loss, acc).\n",
        "    \"\"\"\n",
        "    def loss_fn(params):\n",
        "        logits = model.apply({\"params\": params}, x)\n",
        "        loss, metrics = loss_and_metrics(logits, y)\n",
        "        return loss, metrics\n",
        "\n",
        "    # compute gradients (loss is scalar, metrics is auxiliary)\n",
        "    (loss, metrics), grads = jax.value_and_grad(loss_fn, has_aux=True)(params)\n",
        "\n",
        "    # optax update: compute parameter updates and new optimizer state\n",
        "    updates, new_opt_state = tx.update(grads, opt_state, params)\n",
        "    new_params = optax.apply_updates(params, updates)\n",
        "    return new_params, new_opt_state, metrics\n",
        "\n",
        "# jit: last argument should be static because it is an object\n",
        "train_step = jax.jit(train_step, static_argnames=(\"tx\",))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "269d8e59",
      "metadata": {
        "id": "269d8e59"
      },
      "source": [
        "# Batch creation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "beb30f4e",
      "metadata": {
        "id": "beb30f4e"
      },
      "outputs": [],
      "source": [
        "# create a batch from the training data\n",
        "def get_batch(text_int, B, T):\n",
        "    \"\"\"Create a random batch of data from text_int.\n",
        "\n",
        "    Args:\n",
        "      text_int: 1D array of token ids.\n",
        "      B: batch size (number of sequences).\n",
        "      T: sequence length (number of tokens per sequence).\n",
        "\n",
        "    Returns:\n",
        "      x: (B, T) int array input tokens.\n",
        "      y: (B, T) int array target tokens.\n",
        "    \"\"\"\n",
        "    # choose random starting indices for each sequence in the batch\n",
        "    ix = np.random.randint(0, len(text_int) - T, size=B)\n",
        "    # inputs are text from i to i+T\n",
        "    x = np.stack([text_int[i:i+T] for i in ix])\n",
        "    # targets are text from i+1 to i+T+1\n",
        "    y = np.stack([text_int[i+1:i+T+1] for i in ix])\n",
        "    return jnp.array(x, dtype=jnp.int32), jnp.array(y, dtype=jnp.int32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46c4d034",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper function for counting parameters\n",
        "def count_params(params):\n",
        "    return sum(x.size for x in jax.tree_util.tree_leaves(params))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5da80db",
      "metadata": {
        "id": "f5da80db"
      },
      "source": [
        "# Position Encoding Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "340e8a4c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "340e8a4c",
        "outputId": "4a97fd8e-b10f-4b29-d4fd-5fb5543ce688"
      },
      "outputs": [],
      "source": [
        "def train_model_with_config(pos_encoding_type, niter=5000, B=128, T=32, \n",
        "                           d_model=256, n_layers=2, n_heads=8, \n",
        "                           max_len=128, learning_rate=0.001,\n",
        "                           eval_interval=100, seed=42):\n",
        "    \"\"\"\n",
        "    Train a model with specified positional encoding type and return results.\n",
        "    \n",
        "    Args:\n",
        "        pos_encoding_type: 'learned', 'sinusoidal', 'rotary', or 'none'\n",
        "        niter: Number of training iterations\n",
        "        B: Batch size\n",
        "        T: Sequence length\n",
        "        d_model: Hidden dimension\n",
        "        n_layers: Number of transformer layers\n",
        "        n_heads: Number of attention heads\n",
        "        max_len: Maximum sequence length\n",
        "        learning_rate: Learning rate for optimizer\n",
        "        eval_interval: How often to evaluate on test set\n",
        "        seed: Random seed for reproducibility\n",
        "        \n",
        "    Returns:\n",
        "        Dictionary with training history and final model/params\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Training with {pos_encoding_type.upper()} positional encoding\")\n",
        "    print(f\"{'='*70}\")\n",
        "    \n",
        "    # Initialize random key\n",
        "    local_key = jax.random.PRNGKey(seed)\n",
        "    \n",
        "    # Create model\n",
        "    model, params = create_train_state(\n",
        "        local_key, \n",
        "        vocab_size=vocab_size, \n",
        "        d_model=d_model, \n",
        "        n_layers=n_layers, \n",
        "        n_heads=n_heads, \n",
        "        max_len=max_len,\n",
        "        pos_encoding_type=pos_encoding_type\n",
        "    )\n",
        "    \n",
        "    # Print model info\n",
        "    n_params = count_params(params)\n",
        "    print(f\"Number of parameters: {n_params:_}\")\n",
        "    \n",
        "    # Create optimizer\n",
        "    tx = optax.adam(learning_rate=learning_rate)\n",
        "    opt_state = tx.init(params)\n",
        "    \n",
        "    # Training history\n",
        "    history = {\n",
        "        'iteration': [],\n",
        "        'time': [],\n",
        "        'train_loss': [],\n",
        "        'train_acc': [],\n",
        "        'train_acc_last': [],\n",
        "        'test_loss': [],\n",
        "        'test_acc': [],\n",
        "        'test_acc_last': [],\n",
        "    }\n",
        "    \n",
        "    time_start = time.time()\n",
        "    \n",
        "    # Training loop\n",
        "    for it in range(niter):\n",
        "        # Get batch\n",
        "        batch = get_batch(train_text_int, B, T)\n",
        "        input_tokens, target_tokens = batch[0], batch[1]\n",
        "        \n",
        "        # Training step\n",
        "        params, opt_state, metrics = train_step(\n",
        "            params, opt_state, input_tokens, target_tokens, tx\n",
        "        )\n",
        "        \n",
        "        # Evaluate at intervals\n",
        "        if it % eval_interval == 0 or it == niter - 1:\n",
        "            time_elapsed = time.time() - time_start\n",
        "            \n",
        "            # Compute test metrics\n",
        "            B_test, T_test = 1024, 32\n",
        "            test_batch = get_batch(test_text_int, B_test, T_test)\n",
        "            test_input, test_target = test_batch[0], test_batch[1]\n",
        "            test_logits = model.apply({\"params\": params}, test_input)\n",
        "            test_loss, test_metrics = loss_and_metrics(test_logits, test_target)\n",
        "            \n",
        "            # Store history\n",
        "            history['iteration'].append(it)\n",
        "            history['time'].append(time_elapsed)\n",
        "            history['train_loss'].append(float(metrics['loss']))\n",
        "            history['train_acc'].append(float(metrics['acc']))\n",
        "            history['train_acc_last'].append(float(metrics['acc_last']))\n",
        "            history['test_loss'].append(float(test_loss))\n",
        "            history['test_acc'].append(float(test_metrics['acc']))\n",
        "            history['test_acc_last'].append(float(test_metrics['acc_last']))\n",
        "            \n",
        "            # Print progress\n",
        "            print(f\"Iter {it:5d}/{niter} | Time: {time_elapsed:6.1f}s | \"\n",
        "                  f\"Train Loss: {metrics['loss']:.4f} | Test Loss: {test_loss:.4f} | \"\n",
        "                  f\"Train Acc: {100*metrics['acc']:.1f}% | Test Acc: {100*test_metrics['acc']:.1f}%\")\n",
        "    \n",
        "    print(f\"\\nTraining completed in {time.time() - time_start:.1f} seconds\")\n",
        "    print(f\"Final test accuracy: {100*history['test_acc'][-1]:.2f}%\")\n",
        "    print(f\"Final test accuracy (last char): {100*history['test_acc_last'][-1]:.2f}%\")\n",
        "    \n",
        "    return {\n",
        "        'model': model,\n",
        "        'params': params,\n",
        "        'history': history,\n",
        "        'pos_encoding_type': pos_encoding_type,\n",
        "        'config': {\n",
        "            'niter': niter,\n",
        "            'B': B,\n",
        "            'T': T,\n",
        "            'd_model': d_model,\n",
        "            'n_layers': n_layers,\n",
        "            'n_heads': n_heads,\n",
        "            'max_len': max_len,\n",
        "            'learning_rate': learning_rate,\n",
        "            'n_params': n_params,\n",
        "        }\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9d02d2f",
      "metadata": {},
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bc719ad",
      "metadata": {},
      "outputs": [],
      "source": [
        "NITER = 5000\n",
        "BATCH_SIZE = 128\n",
        "SEQ_LENGTH = 32\n",
        "EVAL_INTERVAL = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "543e8521",
      "metadata": {},
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cb8d917",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Positional encoding types to test\n",
        "encoding_types = ['learned', 'sinusoidal', 'none']\n",
        "\n",
        "# Store results\n",
        "results = {}\n",
        "\n",
        "# Run experiments\n",
        "for encoding_type in encoding_types:\n",
        "    results[encoding_type] = train_model_with_config(\n",
        "        pos_encoding_type=encoding_type,\n",
        "        niter=NITER,\n",
        "        B=BATCH_SIZE,\n",
        "        T=SEQ_LENGTH,\n",
        "        d_model=d_model,  # Use the values defined earlier\n",
        "        n_layers=n_layers,\n",
        "        n_heads=n_heads,\n",
        "        max_len=max_len,\n",
        "        learning_rate=learning_rate,\n",
        "        eval_interval=EVAL_INTERVAL,\n",
        "        seed=42\n",
        "    )\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ALL EXPERIMENTS COMPLETED\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b519444",
      "metadata": {},
      "source": [
        "# Plotting & Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "580f8d8e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a comprehensive figure with multiple subplots\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "fig.suptitle('Positional Encoding Comparison', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Define colors for each encoding type\n",
        "colors = {\n",
        "    'learned': '#2E86AB',\n",
        "    'sinusoidal': '#A23B72',\n",
        "    'none': '#F18F01',\n",
        "    'rotary': '#06A77D'\n",
        "}\n",
        "\n",
        "# 1. Training Loss vs Iterations\n",
        "ax = axes[0, 0]\n",
        "for enc_type, result in results.items():\n",
        "    history = result['history']\n",
        "    ax.plot(history['iteration'], history['train_loss'], \n",
        "            label=enc_type.capitalize(), color=colors[enc_type], \n",
        "            linewidth=2, alpha=0.8)\n",
        "ax.set_xlabel('Iteration', fontsize=11)\n",
        "ax.set_ylabel('Training Loss', fontsize=11)\n",
        "ax.set_title('Training Loss Over Time', fontweight='bold')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Test Loss vs Iterations\n",
        "ax = axes[0, 1]\n",
        "for enc_type, result in results.items():\n",
        "    history = result['history']\n",
        "    ax.plot(history['iteration'], history['test_loss'], \n",
        "            label=enc_type.capitalize(), color=colors[enc_type], \n",
        "            linewidth=2, alpha=0.8)\n",
        "ax.set_xlabel('Iteration', fontsize=11)\n",
        "ax.set_ylabel('Test Loss', fontsize=11)\n",
        "ax.set_title('Test Loss Over Time', fontweight='bold')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Training Accuracy vs Iterations\n",
        "ax = axes[0, 2]\n",
        "for enc_type, result in results.items():\n",
        "    history = result['history']\n",
        "    acc_percent = [a * 100 for a in history['train_acc']]\n",
        "    ax.plot(history['iteration'], acc_percent, \n",
        "            label=enc_type.capitalize(), color=colors[enc_type], \n",
        "            linewidth=2, alpha=0.8)\n",
        "ax.set_xlabel('Iteration', fontsize=11)\n",
        "ax.set_ylabel('Training Accuracy (%)', fontsize=11)\n",
        "ax.set_title('Training Accuracy Over Time', fontweight='bold')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Test Accuracy vs Iterations\n",
        "ax = axes[1, 0]\n",
        "for enc_type, result in results.items():\n",
        "    history = result['history']\n",
        "    acc_percent = [a * 100 for a in history['test_acc']]\n",
        "    ax.plot(history['iteration'], acc_percent, \n",
        "            label=enc_type.capitalize(), color=colors[enc_type], \n",
        "            linewidth=2, alpha=0.8)\n",
        "ax.set_xlabel('Iteration', fontsize=11)\n",
        "ax.set_ylabel('Test Accuracy (%)', fontsize=11)\n",
        "ax.set_title('Test Accuracy Over Time', fontweight='bold')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# 5. Last Character Accuracy (Test) - Most Important Metric\n",
        "ax = axes[1, 1]\n",
        "for enc_type, result in results.items():\n",
        "    history = result['history']\n",
        "    acc_percent = [a * 100 for a in history['test_acc_last']]\n",
        "    ax.plot(history['iteration'], acc_percent, \n",
        "            label=enc_type.capitalize(), color=colors[enc_type], \n",
        "            linewidth=2, alpha=0.8)\n",
        "ax.set_xlabel('Iteration', fontsize=11)\n",
        "ax.set_ylabel('Test Accuracy (Last Char) (%)', fontsize=11)\n",
        "ax.set_title('Next-Character Prediction Accuracy', fontweight='bold')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# 6. Training Time Comparison\n",
        "ax = axes[1, 2]\n",
        "for enc_type, result in results.items():\n",
        "    history = result['history']\n",
        "    ax.plot(history['time'], history['test_loss'], \n",
        "            label=enc_type.capitalize(), color=colors[enc_type], \n",
        "            linewidth=2, alpha=0.8)\n",
        "ax.set_xlabel('Training Time (seconds)', fontsize=11)\n",
        "ax.set_ylabel('Test Loss', fontsize=11)\n",
        "ax.set_title('Test Loss vs Training Time', fontweight='bold')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('positional_encoding_comparison.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nFigure saved as 'positional_encoding_comparison.png'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f125cd9",
      "metadata": {},
      "source": [
        "# Summary Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7e2228f",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*90)\n",
        "print(\"FINAL RESULTS SUMMARY\")\n",
        "print(\"=\"*90)\n",
        "print(f\"{'Encoding Type':<20} {'Parameters':<15} {'Train Loss':<12} {'Test Loss':<12} \"\n",
        "      f\"{'Test Acc':<12} {'Last Char Acc':<15} {'Time (s)':<10}\")\n",
        "print(\"-\"*90)\n",
        "\n",
        "for enc_type, result in results.items():\n",
        "    history = result['history']\n",
        "    config = result['config']\n",
        "    \n",
        "    final_train_loss = history['train_loss'][-1]\n",
        "    final_test_loss = history['test_loss'][-1]\n",
        "    final_test_acc = history['test_acc'][-1] * 100\n",
        "    final_test_acc_last = history['test_acc_last'][-1] * 100\n",
        "    final_time = history['time'][-1]\n",
        "    n_params = config['n_params']\n",
        "    \n",
        "    print(f\"{enc_type.capitalize():<20} {n_params:<15,} {final_train_loss:<12.4f} \"\n",
        "          f\"{final_test_loss:<12.4f} {final_test_acc:<12.2f}% {final_test_acc_last:<15.2f}% \"\n",
        "          f\"{final_time:<10.1f}\")\n",
        "\n",
        "print(\"=\"*90)\n",
        "\n",
        "# Find best performing model\n",
        "best_enc_type = max(results.keys(), \n",
        "                    key=lambda k: results[k]['history']['test_acc_last'][-1])\n",
        "best_acc = results[best_enc_type]['history']['test_acc_last'][-1] * 100\n",
        "\n",
        "print(f\"\\n🏆 Best performing encoding: {best_enc_type.upper()} \"\n",
        "      f\"with {best_acc:.2f}% next-character prediction accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2102c3fe",
      "metadata": {},
      "source": [
        "# Individual plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "732b1b26",
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_detailed_comparison(results, metric='test_acc_last', title='Test Accuracy (Last Character)'):\n",
        "    \"\"\"Create a detailed plot for a specific metric.\"\"\"\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    \n",
        "    for enc_type, result in results.items():\n",
        "        history = result['history']\n",
        "        \n",
        "        if 'acc' in metric:\n",
        "            values = [v * 100 for v in history[metric]]\n",
        "            ylabel = 'Accuracy (%)'\n",
        "        else:\n",
        "            values = history[metric]\n",
        "            ylabel = 'Loss'\n",
        "        \n",
        "        plt.plot(history['iteration'], values, \n",
        "                label=f\"{enc_type.capitalize()}\", \n",
        "                color=colors[enc_type],\n",
        "                linewidth=2.5, alpha=0.85, marker='o', markersize=3, markevery=5)\n",
        "    \n",
        "    plt.xlabel('Iteration', fontsize=12, fontweight='bold')\n",
        "    plt.ylabel(ylabel, fontsize=12, fontweight='bold')\n",
        "    plt.title(title, fontsize=14, fontweight='bold')\n",
        "    plt.legend(fontsize=11, framealpha=0.9)\n",
        "    plt.grid(True, alpha=0.3, linestyle='--')\n",
        "    plt.tight_layout()\n",
        "    \n",
        "    filename = f\"detailed_{metric}.png\"\n",
        "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(f\"Saved: {filename}\")\n",
        "\n",
        "# Create detailed plots for key metrics\n",
        "plot_detailed_comparison(results, 'test_acc_last', \n",
        "                        'Next-Character Prediction Accuracy (Test Set)')\n",
        "plot_detailed_comparison(results, 'test_loss', \n",
        "                        'Test Loss Comparison')\n",
        "plot_detailed_comparison(results, 'train_loss', \n",
        "                        'Training Loss Comparison')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87df4f31",
      "metadata": {},
      "source": [
        "# Generate Sample Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c959313a",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TEXT GENERATION COMPARISON\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "prompts = [\n",
        "    \"the quick brown\",\n",
        "    \"hello world\",\n",
        "    \"once upon a time\"\n",
        "]\n",
        "\n",
        "for prompt in prompts:\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Prompt: '{prompt}'\")\n",
        "    print('='*70)\n",
        "    \n",
        "    for enc_type, result in results.items():\n",
        "        model = result['model']\n",
        "        params = result['params']\n",
        "        \n",
        "        # Encode prompt\n",
        "        prompt_int = jnp.array(\n",
        "            [[char_to_int.get(c, 0) for c in prompt.lower()[:64]]], \n",
        "            dtype=jnp.int32\n",
        "        )\n",
        "        \n",
        "        # Generate\n",
        "        rng = jax.random.PRNGKey(42)\n",
        "        gen_len = 100\n",
        "        out_ids = generation.generate_tokens(\n",
        "            model, params, rng, prompt_int, gen_len, \n",
        "            block_size=max_len, temperature=0.7, sample=True\n",
        "        )\n",
        "        \n",
        "        # Decode\n",
        "        generated_text = ''.join(\n",
        "            int_to_char.get(int(x), '?') for x in list(out_ids[0])\n",
        "        )\n",
        "        full_text = prompt + generated_text\n",
        "        \n",
        "        print(f\"\\n{enc_type.upper()}:\")\n",
        "        print(f\"{full_text[:150]}...\")  # Print first 150 chars"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V5E1",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
